{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task 3 : To explore unsupervised machine learning using Clustering\n    Problem : Given a dataset (IRIS), analyze and explore it to virtually represent the clusters.\n    \n    We will be applying K-Means algorithm. It is a partition-based method of clustering and is very popular for its simplicity"},{"metadata":{},"cell_type":"markdown","source":"STEP 1 : Import the required libraries and dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn import datasets\n\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom sklearn.datasets.samples_generator import make_blobs\n\n\n#load iris dataset\niris = datasets.load_iris()\ndataset = pd.DataFrame(iris.data, columns = iris.feature_names)\ndataset.head(12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"STEP 2 : Visualizing the datset to find any pattern, anomaly or discrepancy in data."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"X = iris.data[:, :2]\ny = iris.target\n\nplt.scatter(X[:,0], X[:,1], c=y, cmap='gist_rainbow')\nplt.xlabel('Sepal Length', fontsize=18)\nplt.ylabel('Sepal Width', fontsize=18)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"STEP 3: Find the optimal number of clusters for the dataset.\n         This is done using the *Silhoutte* score. Finding the score on various values of k, we will see a pattern of increment/decrement in value,k is chosen where the          pattern changes. Hence it is also known as **The Elbow Method**. As it appears as a elbow structure. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding the value of K for applying K- Means Algorithm using The Elbow Method\n\n# Generate 2D data points\nX, _ = make_blobs(n_samples=10, centers=3, n_features=2,\n                 cluster_std=0.2,  random_state=0)\n\nmodel = KMeans(random_state = 0)\n\nvisualizer = KElbowVisualizer(model, k=(2,6), metric='silhouette', timings=False)\n\n# Fit the data and visualize\nvisualizer.fit(X)    \nvisualizer.poof() \n\nprint(\"As the graph shows a turn on k = 3, the most optimal value of k is 3\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"STEP 4: We apply the clustering algorithm and visualize the clusters formed using the matplotlib library."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the cluster centers and the data points on a 2D plane\n\nx= iris.data[:, :2]\ny_pred = model.fit_predict(x)\n\n#Visualization the clusters \n\nplt.scatter(x[y_kmeans == 0, 0], x[y_pred == 0, 1], s = 100, c = 'red' , label = 'Iris-setosa')\nplt.scatter(x[y_kmeans == 1, 0], x[y_pred == 1, 1], s = 100, c = 'blue' , label = 'Iris-versicolor')\nplt.scatter(x[y_kmeans == 2, 0], x[y_pred == 2, 1], s = 100, c = 'green' , label = 'Iris-virginica')\n\n#plot centroids\n\nplt.scatter(model.cluster_centers_[:, 0], model.cluster_centers_[:, 1], s = 100, c = 'yellow', label = 'Centroids')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}